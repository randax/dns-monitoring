# DNS Monitoring Configuration File
# This file configures the DNS monitoring tool behavior
# 
# Example configuration demonstrating various DNS protocols and monitoring options

# DNS Configuration
dns:
  # List of DNS servers to monitor
  servers:
    - name: "Google Primary"
      address: "8.8.8.8"
      port: 53
      protocol: "udp"  # Options: udp, tcp, dot, doh
      enabled: true
    
    - name: "Google Secondary"
      address: "8.8.4.4"
      port: 53
      protocol: "tcp"  # Using TCP protocol
      enabled: true
    
    - name: "Cloudflare Primary"
      address: "1.1.1.1"
      port: 53
      protocol: "udp"
      enabled: true
    
    - name: "Cloudflare DoT"
      address: "1.1.1.1"
      port: 853  # DNS over TLS uses port 853
      protocol: "dot"
      insecure_skip_verify: false  # Set to true to skip TLS certificate verification
      enabled: true
    
    - name: "Cloudflare DoH"
      address: "https://cloudflare-dns.com"
      port: 443
      protocol: "doh"
      doh_endpoint: "/dns-query"  # Optional, defaults to /dns-query
      doh_method: "POST"  # Optional, defaults to POST. Options: GET, POST
      insecure_skip_verify: false  # Set to true to skip TLS certificate verification
      enabled: true
    
    - name: "Google DoH"
      address: "https://dns.google"
      port: 443
      protocol: "doh"
      doh_endpoint: "/dns-query"
      doh_method: "GET"  # Using GET method for DNS queries
      insecure_skip_verify: false  # Set to true to skip TLS certificate verification
      enabled: false
    
    - name: "Quad9"
      address: "9.9.9.9"
      port: 53
      protocol: "udp"
      enabled: false

  # Query configuration
  queries:
    # DNS record types to query
    types:
      - "A"
      - "AAAA"
      - "MX"
      - "TXT"
      - "NS"
      - "CNAME"
    
    # Domains to test DNS resolution
    domains:
      - "example.com"
      - "google.com"
      - "cloudflare.com"
      - "github.com"
      - "stackoverflow.com"
    
    # Query timeout in seconds
    timeout: 5s
    
    # Number of retries for failed queries
    retries: 3

# Monitoring Configuration
monitor:
  # Interval between monitoring cycles
  interval: 30s
  
  # Maximum concurrent DNS queries
  max_concurrent: 10
  
  # Number of consecutive failures before alerting
  alert_threshold: 3

# Output Configuration
output:
  # Output format: json, text, or csv
  format: "json"
  
  # Log file path (optional)
  file: "dns-monitor.log"
  
  # Enable console output
  console: true
  
  # Buffer size for output queue
  buffer_size: 1000
  
  # Metrics configuration
  metrics:
    # Enable metrics export
    enabled: false
    
    # Metrics endpoint (for Prometheus)
    endpoint: "http://localhost:9090/metrics"
    
    # Metrics push interval in seconds
    interval: 60
  
  # CLI formatter configuration
  cli:
    # Enable color output (ANSI color codes)
    show_colors: true
    
    # Show detailed metrics view
    detailed_view: false
    
    # Refresh interval for real-time monitoring (minimum 1s)
    refresh_interval: 10s
    
    # Compact mode for minimal output
    compact_mode: false
    
    # Show query type and response code distributions
    show_distributions: true

# Metrics collection configuration
metrics:
  # Sliding window duration for metrics calculation
  window_duration: 5m
  
  # Maximum number of data points to retain
  max_data_points: 10000
  
  # Enable percentile calculations
  calculate_percentiles: true
  
  # Percentiles to calculate
  percentiles:
    - 50   # P50 (median)
    - 95   # P95
    - 99   # P99
    - 99.9 # P999
  
  # Enable per-server metrics
  per_server_metrics: true
  
  # Enable query type distribution tracking
  track_query_types: true
  
  # Enable response code distribution tracking
  track_response_codes: true
  
  # QPS (Queries Per Second) calculation interval
  qps_interval: 10s
  
  # Export settings for external systems
  export:
    # Prometheus export configuration
    # Prometheus is a powerful open-source monitoring and alerting toolkit
    # When enabled, DNS metrics will be exposed in Prometheus format
    prometheus:
      # Enable Prometheus metrics export
      enabled: true
      
      # Port for the Prometheus HTTP server
      # Prometheus will scrape metrics from http://hostname:port/metrics
      port: 9090
      
      # Path where metrics will be exposed
      # Default: /metrics (standard Prometheus path)
      path: "/metrics"
      
      # How often to update metrics (should be less than Prometheus scrape interval)
      update_interval: 30s
      
      # Include server name as a label in metrics
      # This allows filtering and grouping by DNS server
      include_server_labels: true
      
      # Include protocol (udp, tcp, dot, doh) as a label
      # Useful for comparing performance across different protocols
      include_protocol_labels: true
      
      # Prefix for all metric names (default: dns)
      # Metrics will be named like: dns_queries_total, dns_latency_seconds, etc.
      # Allowed characters: letters (a-z, A-Z), numbers (0-9), underscore (_), and colon (:)
      # Colons are commonly used in recording rules and aggregations
      metric_prefix: "dns"
      
      # Advanced metric features configuration
      # By default, only core DNS metrics are enabled (latency, QPS, success rates, response codes)
      # Enable individual features below for additional insights at the cost of increased memory usage
      metric_features:
        # Cache performance metrics (hit rate, efficiency, TTL distributions)
        # Useful for understanding recursive resolver behavior
        enable_cache_metrics: false
        
        # Network analysis metrics (packet loss, quality score, interface-level stats)
        # Helpful for diagnosing network-related DNS issues
        enable_network_metrics: false
        
        # Jitter tracking (P50, P95, P99 of latency variations)
        # Important for detecting DNS instability
        enable_jitter_metrics: false
        
        # TTL analysis (min, max, average TTL values)
        # Useful for cache optimization and understanding record lifecycles
        enable_ttl_metrics: false
        
        # Monitor health metrics (CPU, memory, goroutines, buffer usage)
        # Helps track the monitoring tool's own resource usage
        enable_monitoring_metrics: false
      
      # Enable tracking of individual latency samples for histogram/summary metrics
      # When false (default), only percentile gauges are populated (lower overhead)
      # When true, individual samples are tracked for histogram/summary metrics
      enable_latency_sampling: false
    
    # Adaptive sampling configuration for memory usage control
    adaptive_sampling:
      # Enable adaptive sampling based on query volume and memory pressure
      enabled: true
      
      # Minimum sampling rate (0.0-1.0)
      # Even under high load, at least this fraction of queries will be sampled
      min_sample_rate: 0.001
      
      # Maximum sampling rate (0.0-1.0) 
      # Even under low load, at most this fraction of queries will be sampled
      max_sample_rate: 1.0
      
      # Target sampling rate when conditions are normal
      target_sample_rate: 0.1
      
      # Maximum memory to use for latency sample buffers (in MB)
      memory_limit_mb: 100
      
      # How often to adjust the sampling rate based on conditions
      adjust_interval: 30s
      
      # Time window for calculating query rates
      window_duration: 5m
      
      # QPS threshold for high-volume traffic
      high_volume_qps: 1000
      
      # QPS threshold for low-volume traffic
      low_volume_qps: 10
      
      # Memory pressure threshold (0.0-1.0)
      # When memory usage exceeds this fraction, sampling is reduced
      memory_pressure_threshold: 0.8
      
      # Available Prometheus metrics:
      # Always available:
      # - dns_queries_total: Total number of DNS queries (counter)
      # - dns_queries_success_total: Total successful queries (counter)
      # - dns_queries_error_total: Total failed queries (counter)
      # - dns_response_codes_total: Response codes distribution (counter)
      # - dns_query_types_total: Query types distribution (counter)
      # - dns_queries_per_second: Current QPS (gauge)
      # - dns_success_rate_ratio: Success rate 0-1 (gauge)
      # - dns_error_rate_ratio: Error rate 0-1 (gauge)
      # - dns_latency_p50_seconds: 50th percentile latency (gauge)
      # - dns_latency_p95_seconds: 95th percentile latency (gauge)
      # - dns_latency_p99_seconds: 99th percentile latency (gauge)
      # - dns_latency_p999_seconds: 99.9th percentile latency (gauge)
      #
      # Only populated when enable_latency_sampling is true:
      # - dns_query_duration_seconds: Query latency histogram with buckets
      # - dns_query_duration_summary_seconds: Query latency summary with quantiles
      
      # Example Prometheus configuration to scrape these metrics:
      # scrape_configs:
      #   - job_name: 'dns_monitoring'
      #     static_configs:
      #       - targets: ['localhost:9090']
      #     scrape_interval: 60s
    
    # Zabbix export configuration
    # Zabbix is an enterprise-class monitoring solution for networks and applications
    # When enabled, DNS metrics will be sent to Zabbix server using Zabbix sender protocol
    zabbix:
      # Enable Zabbix metrics export
      enabled: false
      
      # Zabbix server or proxy address
      # This is where the DNS monitoring data will be sent
      server: "localhost"
      
      # Zabbix server or proxy port (default: 10051)
      port: 10051
      
      # Hostname as configured in Zabbix
      # This must match the host name configured in Zabbix server
      # The host should be created in Zabbix before starting the monitoring
      hostname: "dns-monitor"
      
      # How often to send metrics to Zabbix
      # Should align with your Zabbix item update intervals
      send_interval: 60s
      
      # Batch size for sending items
      # Larger batches are more efficient but may hit size limits
      batch_size: 100
      
      # Connection timeout for Zabbix server
      timeout: 10s
      
      # Number of retry attempts if sending fails
      retry_attempts: 3
      
      # Delay between retry attempts
      retry_delay: 5s
      
      # Prefix for all Zabbix item names (default: dns)
      # Items will be named like: dns.latency.p50, dns.success_rate, etc.
      item_prefix: "dns"
      
      # Zabbix items that will be created:
      # Latency metrics (in milliseconds):
      # - dns.latency.p50: 50th percentile (median) latency
      # - dns.latency.p95: 95th percentile latency
      # - dns.latency.p99: 99th percentile latency
      # - dns.latency.p999: 99.9th percentile latency
      # - dns.latency.avg: Average latency
      # - dns.latency.min: Minimum latency
      # - dns.latency.max: Maximum latency
      #
      # Rate metrics (percentages 0-100):
      # - dns.success_rate: Percentage of successful queries
      # - dns.error_rate: Percentage of failed queries
      #
      # Throughput metrics:
      # - dns.qps.current: Current queries per second
      # - dns.qps.avg: Average queries per second
      # - dns.qps.peak: Peak queries per second
      #
      # Volume metrics:
      # - dns.queries.total: Total number of queries
      # - dns.queries.success: Total successful queries
      # - dns.queries.error: Total failed queries
      #
      # Response code distribution (count):
      # - dns.response_code.noerror: NOERROR responses
      # - dns.response_code.nxdomain: NXDOMAIN responses
      # - dns.response_code.servfail: SERVFAIL responses
      # - dns.response_code.refused: REFUSED responses
      # - dns.response_code.other: Other response codes
      #
      # Query type distribution (count):
      # - dns.query_type.a: A record queries
      # - dns.query_type.aaaa: AAAA record queries
      # - dns.query_type.mx: MX record queries
      # - dns.query_type.txt: TXT record queries
      # - dns.query_type.ns: NS record queries
      # - dns.query_type.cname: CNAME record queries
      # - dns.query_type.other: Other query types
      #
      # Per-server metrics (if enabled):
      # - dns.server.{server_name}.latency: Server-specific latency
      # - dns.server.{server_name}.success_rate: Server-specific success rate
      # - dns.server.{server_name}.qps: Server-specific QPS
      #
      # Zabbix server configuration:
      # 1. Create a host in Zabbix with the same name as 'hostname' above
      # 2. Create item prototypes or individual items for each metric
      # 3. Set item type to "Zabbix trapper" for all DNS metrics
      # 4. Configure triggers based on thresholds (e.g., latency > 100ms)
      # 5. Create graphs and dashboards to visualize the metrics
      #
      # Example Zabbix item configuration:
      # Name: DNS P95 Latency
      # Key: dns.latency.p95
      # Type: Zabbix trapper
      # Type of information: Numeric (float)
      # Units: ms
      # Update interval: 60s (passive, updated by sender)
    
    # StatsD export
    statsd:
      enabled: false
      address: "localhost:8125"
      prefix: "dns_monitor"
    
    # JSON file export
    json:
      enabled: false
      path: "metrics.json"
      interval: 60s

# Passive Monitoring Configuration
# Captures and analyzes DNS traffic from network interfaces without sending queries
passive:
  # Enable passive DNS monitoring
  # Note: Requires root/admin privileges or CAP_NET_RAW capability
  enabled: false
  
  # Network interfaces to monitor
  # Empty list means auto-detect all available non-loopback interfaces
  # Examples: ["eth0", "en0", "wlan0"]
  interfaces: []
  
  # Berkeley Packet Filter (BPF) expression for traffic filtering
  # Default captures all DNS traffic on port 53
  # Examples:
  #   "port 53" - All DNS traffic (UDP and TCP)
  #   "udp port 53" - Only UDP DNS traffic
  #   "tcp port 53" - Only TCP DNS traffic
  #   "port 53 and host 8.8.8.8" - DNS traffic to/from specific server
  #   "port 53 and not host 192.168.1.1" - Exclude local DNS server
  bpf: "port 53"
  
  # Maximum bytes to capture per packet
  # 262144 is sufficient for most DNS packets including large responses
  snaplen: 262144
  
  # Number of concurrent packet processing workers
  # Increase for high-traffic environments
  workers: 4
  
  # Timeout for matching DNS queries with responses
  # Queries without responses after this timeout are considered failed
  match_timeout: 5s
  
  # Internal packet buffer size
  # Increase if dropping packets in high-traffic scenarios
  buffer_size: 10000
  
  # TCP Stream Reassembly Configuration
  # Optional: Enable TCP stream reassembly for fragmented DNS over TCP
  tcp_reassembly:
    # Enable TCP stream reassembly (disabled by default for lower resource usage)
    enabled: false
    
    # Maximum number of concurrent TCP streams to track
    # Each stream consumes memory, so adjust based on available resources
    max_streams: 1000
    
    # Maximum buffer size per stream in bytes (64KB default)
    # Larger buffers handle bigger DNS responses but consume more memory
    max_buffer_size: 65536
    
    # Maximum total memory for all TCP reassembly buffers (100MB default)
    # Prevents excessive memory usage in high-traffic scenarios
    max_total_memory: 104857600
    
    # How often to flush old/inactive streams
    flush_interval: 5s
    
    # Timeout for inactive TCP streams
    stream_timeout: 30s
    
    # How often to clean up old buffers and enforce resource limits
    cleanup_interval: 10s

# Cache Performance Analysis Configuration
# Analyzes cache behavior of recursive DNS resolvers to identify cache hits and efficiency
cache:
  # Enable cache performance analysis
  enabled: false
  
  # Interval between cache analysis cycles
  # Cache analysis examines response times and TTL values to detect cached responses
  analysis_interval: 30s
  
  # Response time threshold for detecting cache hits
  # Responses faster than this threshold are likely served from cache
  # Typical values: 5-20ms for cache hits vs 50-200ms for authoritative queries
  cache_hit_threshold: 10ms
  
  # List of recursive DNS servers to analyze for cache performance
  # These should be server names from the DNS servers list above
  # Leave empty to analyze all configured servers
  recursive_servers: []
    # - "Google Primary"
    # - "Cloudflare Primary"
  
  # Track TTL values to detect cache behavior
  # When enabled, monitors TTL decrements to identify cached responses
  ttl_tracking: true
  
  # Calculate cache efficiency metrics
  # Includes hit rate, miss rate, and cache effectiveness score
  cache_efficiency_metrics: true
  
  # Cache detection methods to use
  # Available methods:
  #   - "timing": Detect cache hits based on response time patterns
  #   - "ttl": Track TTL decrements to identify cached responses  
  #   - "pattern": Analyze response patterns for cache detection
  detection_methods:
    - "timing"
    - "ttl"
    - "pattern"
  
  # Cache Analysis Concepts:
  # - Cache Hit: DNS response served from resolver's cache (fast, low latency)
  # - Cache Miss: Query forwarded to authoritative server (slower, higher latency)
  # - Cache Efficiency: Ratio of cache hits to total queries (higher is better)
  # - TTL Tracking: Monitors time-to-live values decreasing over time
  # - Cache Age: Estimated time since response was cached
  #
  # When to Enable:
  # - Testing recursive resolver performance
  # - Optimizing DNS caching strategies
  # - Troubleshooting intermittent slowness
  # - Validating cache configuration changes
  #
  # Performance Impact:
  # - Minimal overhead when using timing-based detection
  # - TTL tracking requires storing historical data
  # - Pattern analysis may increase CPU usage slightly

# Network-Level Metrics Configuration
# Monitors packet loss, jitter, and network quality for DNS communications
network:
  # Enable network-level metrics collection
  enabled: false
  
  # Enable packet loss detection
  # Tracks sent queries vs received responses to calculate loss percentage
  packet_loss_detection: false
  
  # Enable jitter calculation
  # Measures variation in response times to detect network instability
  jitter_calculation: false
  
  # Enable ping integration for network path analysis
  # Uses ICMP to measure network latency separately from DNS processing
  ping_integration: false
  
  # Timeout for network operations
  network_timeouts: 10s
  
  # Packet loss threshold for alerting (0.0 to 1.0)
  # 0.05 = 5% packet loss triggers warnings
  packet_loss_threshold: 0.05
  
  # Jitter threshold for network quality assessment
  # High jitter indicates unstable network conditions
  jitter_threshold: 50ms
  
  # Sample size for statistical calculations
  # Larger samples provide more accurate metrics but use more memory
  sample_size: 100
  
  # Network interfaces to monitor (for packet-level analysis)
  # Leave empty to monitor all interfaces
  network_interfaces: []
    # - "eth0"
    # - "wlan0"
  
  # Network Metrics Concepts:
  # - Packet Loss: Percentage of DNS queries without responses
  # - Jitter: Variation in latency over time (standard deviation)
  # - Network Latency: Pure network transit time (excluding DNS processing)
  # - Hop Count: Number of network hops to DNS server
  # - Network Quality Score: Composite metric (0-100) based on loss, jitter, latency
  #
  # Calculation Methods:
  # - Packet Loss: (Sent Queries - Received Responses) / Sent Queries
  # - Jitter: Standard deviation of response times over sample window
  # - Network Quality: 100 - (PacketLoss% * 50 + JitterScore * 30 + LatencyScore * 20)
  #
  # When to Enable:
  # - Diagnosing intermittent DNS failures
  # - Monitoring WAN link quality
  # - Troubleshooting network performance issues
  # - Validating QoS configurations
  #
  # Performance Impact:
  # - Packet loss detection: Low overhead
  # - Jitter calculation: Moderate CPU for statistics
  # - Ping integration: Additional ICMP traffic
  #
  # Privilege Requirements:
  # - Ping integration may require root/admin privileges
  # - Some metrics require CAP_NET_RAW capability on Linux